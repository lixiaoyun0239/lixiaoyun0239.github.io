---
layout: archive
title: "Hello World!"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

My name is Xiaoyun Li. I'm a machine learning scientist at LinkedIn, developing algorithms and theory for big data and machine learning. Before joining Linkedin, I was a research scientist at Baidu Research. 

Education
======
* B.S. Financial Mathematics, Shanghai Jiao Tong University, 2015
* M.S. Financial Statistics and Risk Management, Rutgers University, 2017
* Ph.D Statistics, Rutgers University, 2021\
  I was fortunate to work with <span style="color:blue">[Prof. Ping Li](https://pltrees.github.io/)</span>.\
  Thesis committee: Prof. Ping Li, Prof. Cun-Hui Zhang, Prof. Min Xu, Prof. William Steiger.

Work Experience
======
* Teaching Assistant, Department of Statistics, Rutgers University\
   -- Introduction to Statistics, Advanced Simulation, Data Mining

* Baidu Research Institute

* LinkedIn

Interests
======
Statistics, Machine Learning, Randomized Algorithms, Information Retrieval, Privacy, Distributed Optimization, Deep Learning, Basketball, Guitar... and anything interesting!

Academic Services
======
* Conference Reviewer/PC Member: Since 2020, I have served as the reviewer/PC/SPC for NeurIPS, ICML, ICLR, SODA, AISTATS, KDD, WWW, AAAI, IJCAI conference
* Journal Reviewer: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), Machine Learning, IEEE/CAA Journal of Automatica Sinica

Selected Publications
======
  <ul>{% for post in site.publications %}
    {% include archive-single-cv.html %}
  {% endfor %}</ul>
  
<em>(* : alphabetical order)<em>

**New:**
* **Xiaoyun Li** and Ping Li. <em>Analysis of Error Feedback in Federated Non-convex Optimization with Biased Compression</em>, <span style="color:blue">[[Arxiv](https://arxiv.org/pdf/2211.14292.pdf)]</span>.
* Ping Li and **Xiaoyun Li**. <em>OPORP: One Permutation + One Random Projection</em>, <span style="color:blue">[[Arxiv](https://arxiv.org/pdf/2302.03505.pdf)]</span>.
* Long Feng<sup>*</sup>, Tiefeng Jiang<sup>*</sup>, **Xiaoyun Li<sup>*</sup>** and Binghui Liu<sup>*</sup>. <em>Asymptotic Independence of the Sum and Maximum of Dependent Random Variables with Applications to High-dimensional Tests</em>, <span style="color:blue">Statistica Sinica (2023), [[paper](https://arxiv.org/pdf/2205.01638.pdf)]</span>.
* Farzin Haddadpour<sup>*</sup>, Belhal Karimi<sup>*</sup>, Ping Li<sup>*</sup> and **Xiaoyun Li<sup>*</sup>**. <em>FedSKETCH: Communication-Efficient and Private Federated Learning via Sketching</em>, <span style="color:blue">[[Arxiv](https://arxiv.org/pdf/2008.04975.pdf)]</span>.

**Dimensionality Reduction & Compression:**
* **Xiaoyun Li** and Ping Li. *Generalization Error Analysis of Quantized Compressive Learning*, <span style="color:blue">Neural Information Processing Systems (NeurIPS) 2019 (Oral spotlight), [[paper](https://proceedings.neurips.cc/paper/2019/file/1a638db8311430c6c018bf21e1a0b7fb-Paper.pdf)]</span>.
* **Xiaoyun Li** and Ping Li. *Random Projections with Asymmetric Quantization*, <span style="color:blue">Neural Information Processing Systems (NeurIPS) 2019, [[paper](https://papers.nips.cc/paper/2019/file/a32d7eeaae19821fd9ce317f3ce952a7-Paper.pdf)]</span>.
* **Xiaoyun Li** and Ping Li. *Quantization Algorithms for Random Fourier Features*, <span style="color:blue">International Conference on Machine Learning (ICML) 2021, [[paper](http://proceedings.mlr.press/v139/li21i/li21i.pdf)]</span>.
* **Xiaoyun Li** and Ping Li. *One-Sketch-for-All: Non-linear Random Features from Compressed Linear Measurements*, <span style="color:blue">International Conference on Artificial Intelligence and Statistics (AISTATS) 2021, [[paper](http://proceedings.mlr.press/v130/li21e/li21e.pdf)]</span>.
* **Xiaoyun Li**, Chenxi Wu and Ping Li. *IVFS: Simple and Efficient Feature Selection for High Dimensional Topology Preservation*, <span style="color:blue">AAAI Conference on Artificial Intelligence (AAAI) 2020, [[paper](https://ojs.aaai.org/index.php/AAAI/article/download/5908/5764)]</span>.
* Zhiqiang Xu, Dong Li, Weijie Zhao, Xing Shen, Tianbo Huang, **Xiaoyun Li**, and Ping Li. *Agile and Accurate CTR Prediction Model Training for Massive-Scale Online Advertising Systems*, <span style="color:blue">ACM International Conference on Management of Data (SIGMOD) 2021, [[paper](https://dl.acm.org/doi/pdf/10.1145/3448016.3457236?casa_token=YtCGqkxI5V4AAAAA:qm3Hc8ROpwi0lCXL2qnf4BAbOVqKe08m-kJMAqGNAGBZ-QWo295cNRsD7FWU82bSrri1D9AEfg)]</span>.
  
**Randomized Algorithms, Hashing, Kernel Methods:**
* **Xiaoyun Li** and Ping Li. *SignRFF: Sign Random Fourier Features*, <span style="color:blue">Neural Information Processing Systems (NeurIPS) 2022, [[paper](https://openreview.net/pdf?id=ZfaEZyQDrok)]</span>.
* **Xiaoyun Li** and Ping Li. *C-MinHash: Improving Min-wise Hashing with Circulant Permutation*, <span style="color:blue">International Conference on Machine Learning (ICML) 2022, [[paper](https://proceedings.mlr.press/v162/li22m/li22m.pdf)]</span>.
* Ping Li<sup>*</sup>, **Xiaoyun Li<sup>*</sup>** and Cun-Hui Zhang<sup>*</sup>. <em>Re-randomized Densification for One Permutation Hashing and Bin-wise Consistent Weighted Sampling</em>, <span style="color:blue">Neural Information Processing Systems (NeurIPS) 2019, [[paper](https://proceedings.neurips.cc/paper/2019/file/9f067d8d6df2d4b8c64fb4c084d6c208-Paper.pdf)]</span>.
* Ping Li<sup>*</sup>, **Xiaoyun Li<sup>*</sup>**, Gennady Samorodnitsky<sup>*</sup> and Weijie Zhao<sup>*</sup>. <em>Consistent Sampling Through Extremal Process</em>, <span style="color:blue">The Web Conference (WWW) 2021, [[paper](https://dl.acm.org/doi/pdf/10.1145/3442381.3449955?casa_token=3gq2mIdZS4oAAAAA:UPx2ir3Mbm1YxZlXp_qlAWxlWi-riaSTwsDIavZfKhVF3bohc6KQgtF3-CjmAHS71rSL0C_bzg)]</span>.
* **Xiaoyun Li** and Ping Li. *Rejection Sampling for Weighted Jaccard Similarity Revisited*, <span style="color:blue">AAAI Conference on Artificial Intelligence (AAAI) 2021, [[paper](https://ojs.aaai.org/index.php/AAAI/article/download/16543/16350)]</span>.
* Ping Li<sup>*</sup>, **Xiaoyun Li<sup>*</sup>** and Gennady Samorodnitsky<sup>*</sup>. <em>P-MinHash Algorithm for Continuous Probability Measures: Theory and Application to Machine Learning</em>, <span style="color:blue">Conference on Information and Knowledge Management (CIKM) 2022, [[paper](https://dl.acm.org/doi/10.1145/3511808.3557413)]</span>.
* Peng Yang, **Xiaoyun Li** and Ping Li. *Graph-based Adversarial Online Kernel Learning with Adaptive Embedding*, <span style="color:blue">International Conference on Data Mining (ICDM) 2021, [[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9679067)]</span>.
* **Xiaoyun Li**, Jie Gui and Ping Li. *Randomized Kernel Multi-view Discriminant Analysis*, <span style="color:blue">European Conference on Artificial Intelligence (ECAI) 2020, [[paper](https://ecai2020.eu/papers/1665_paper.pdf)]</span>.

**Distributed/Federated Optimization:**
* **Xiaoyun Li**, Belhal Karimi and Ping Li. *On Distributed Adaptive Optimization with Gradient Compression*, <span style="color:blue">International Conference on Learning Representations (ICLR) 2022, [[paper](https://openreview.net/pdf?id=CI-xXX9dg9l)]</span>.
* Xiangyi Chen, **Xiaoyun Li** and Ping Li. *Towards Communication-Efficient Adaptive Gradient Method*, <span style="color:blue">ACM-IMS Foundations of Data Science Conference (FODS) 2020, [[paper](https://dl.acm.org/doi/pdf/10.1145/3412815.3416891?casa_token=Fw_rn4pY5NUAAAAA:PCj4UKtaMtRSiF16yQV-mkuJeVbaxoIFiy8dz1TApXqMUGJEF_h7xmtqFuxhQlgR0GXBbs0Itw)]</span>.
* Jun-Kun Wang, **Xiaoyun Li**, Belhal Karimi and Ping Li. *An Optimistic Acceleration of AMSGrad for Nonconvex Optimization*, <span style="color:blue">Asian Conference on Machine Learning (ACML) 2021, [[paper](https://proceedings.mlr.press/v157/wang21c/wang21c.pdf)]</span>.
* Weijie Zhao, Xuewu Jiao, Mingqing Hu, **Xiaoyun Li**, Xiangyu Zhang, and Ping Li. *Communication-Efficient Terabyte-Scale Model Training Framework for Online Advertising*, <span style="color:blue">IEEE International Conference on Big Data (IEEE BigData), to appear</span>.
  
  
**Privacy, Causal Inference:**
* Chenglin Fan<sup>*</sup>, Ping Li<sup>*</sup> and **Xiaoyun Li<sup>*</sup>**. <em>Private Graph All-Pairwise-Shortest-Path Distance Release with Improved Error Rate</em>, <span style="color:blue">Neural Information Processing Systems (NeurIPS) 2022, [[paper](https://openreview.net/pdf?id=R2XFXfK0SVe)]</span>.
* Huang Fang, **Xiaoyun Li**, Chenglin Fan and Ping Li. <em>Improved Convergence of Differential Private SGD with Gradient Clipping</em>, <span style="color:blue">International Conference on Learning Representations (ICLR) 2023, [[paper](https://openreview.net/pdf?id=FRLswckPXQ5)]</span>.
* Xueyan Niu, **Xiaoyun Li** and Ping Li. *Learning Cluster Causal Diagrams: An Information-Theoretic Approach*, <span style="color:blue">International Joint Conference on Artificial Intelligence (IJCAI) 2022, [[paper](https://www.ijcai.org/proceedings/2022/0675.pdf)]</span>.
  
**Computer Vision:**
* Tan Yu, **Xiaoyun Li** and Ping Li. *Fast and Compact Bilinear Pooling by Shifted Random Maclaurin*, <span style="color:blue">AAAI Conference on Artificial Intelligence (AAAI) 2021, [[paper](https://ojs.aaai.org/index.php/AAAI/article/download/16435/16242)]</span>.

